{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "460b34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4a5a6",
   "metadata": {},
   "source": [
    "### Import MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "58ed3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d67881",
   "metadata": {},
   "source": [
    "### Basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9f81cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - zero': 0,\n",
       " '1 - one': 1,\n",
       " '2 - two': 2,\n",
       " '3 - three': 3,\n",
       " '4 - four': 4,\n",
       " '5 - five': 5,\n",
       " '6 - six': 6,\n",
       " '7 - seven': 7,\n",
       " '8 - eight': 8,\n",
       " '9 - nine': 9}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e298e9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "549758b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fcd6cce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = training_data[0]\n",
    "img.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f31db",
   "metadata": {},
   "source": [
    "### Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "327d606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e0ab49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f21f1d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Check mps maybe if working in MacOS\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2ffd7",
   "metadata": {},
   "source": [
    "### Create Model with Binary Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9f5ff78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d5899",
   "metadata": {},
   "source": [
    "**Define sign activation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d8c3e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return (input > 0).float()\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return F.hardtanh(grad_output)\n",
    "\n",
    "class StraightThroughEstimator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StraightThroughEstimator, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = STEFunction.apply(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "34271267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): StraightThroughEstimator()\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.1, inplace=False)\n",
      "    (7): StraightThroughEstimator()\n",
      "    (8): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (9): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout(p=0.1, inplace=False)\n",
      "    (11): StraightThroughEstimator()\n",
      "    (12): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (13): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout(p=0.1, inplace=False)\n",
      "    (15): StraightThroughEstimator()\n",
      "    (16): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (17): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class FPNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FPNeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(p=0.1),\n",
    "            StraightThroughEstimator(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(p=0.1),\n",
    "            StraightThroughEstimator(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(p=0.1),\n",
    "            StraightThroughEstimator(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(p=0.1),\n",
    "            StraightThroughEstimator(),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.BatchNorm1d(10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.stack(x)\n",
    "        return F.log_softmax(logits)\n",
    "\n",
    "net = FPNeuralNetwork().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c373e35",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9746c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adamax(net.parameters(), lr=3e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bf694600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = F.nll_loss(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3cadd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += F.nll_loss(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4d2b7133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.709189  [   64/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_9344\\2821843339.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.871715  [ 6464/60000]\n",
      "loss: 0.754001  [12864/60000]\n",
      "loss: 0.788550  [19264/60000]\n",
      "loss: 0.734998  [25664/60000]\n",
      "loss: 0.671158  [32064/60000]\n",
      "loss: 0.567648  [38464/60000]\n",
      "loss: 0.650778  [44864/60000]\n",
      "loss: 0.534939  [51264/60000]\n",
      "loss: 0.678903  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.400633 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.530654  [   64/60000]\n",
      "loss: 0.481726  [ 6464/60000]\n",
      "loss: 0.484848  [12864/60000]\n",
      "loss: 0.581437  [19264/60000]\n",
      "loss: 0.399799  [25664/60000]\n",
      "loss: 0.590558  [32064/60000]\n",
      "loss: 0.337829  [38464/60000]\n",
      "loss: 0.653213  [44864/60000]\n",
      "loss: 0.427863  [51264/60000]\n",
      "loss: 0.707894  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.352422 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.294213  [   64/60000]\n",
      "loss: 0.575122  [ 6464/60000]\n",
      "loss: 0.447706  [12864/60000]\n",
      "loss: 0.526050  [19264/60000]\n",
      "loss: 0.477657  [25664/60000]\n",
      "loss: 0.545274  [32064/60000]\n",
      "loss: 0.433417  [38464/60000]\n",
      "loss: 0.596418  [44864/60000]\n",
      "loss: 0.395257  [51264/60000]\n",
      "loss: 0.621156  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.337534 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.382672  [   64/60000]\n",
      "loss: 0.420737  [ 6464/60000]\n",
      "loss: 0.477123  [12864/60000]\n",
      "loss: 0.557174  [19264/60000]\n",
      "loss: 0.543450  [25664/60000]\n",
      "loss: 0.530743  [32064/60000]\n",
      "loss: 0.400690  [38464/60000]\n",
      "loss: 0.510689  [44864/60000]\n",
      "loss: 0.341412  [51264/60000]\n",
      "loss: 0.542925  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.325839 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.355734  [   64/60000]\n",
      "loss: 0.321164  [ 6464/60000]\n",
      "loss: 0.324706  [12864/60000]\n",
      "loss: 0.438138  [19264/60000]\n",
      "loss: 0.457314  [25664/60000]\n",
      "loss: 0.636682  [32064/60000]\n",
      "loss: 0.439859  [38464/60000]\n",
      "loss: 0.523930  [44864/60000]\n",
      "loss: 0.382078  [51264/60000]\n",
      "loss: 0.571915  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.313177 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.338369  [   64/60000]\n",
      "loss: 0.315061  [ 6464/60000]\n",
      "loss: 0.507750  [12864/60000]\n",
      "loss: 0.421722  [19264/60000]\n",
      "loss: 0.401509  [25664/60000]\n",
      "loss: 0.562227  [32064/60000]\n",
      "loss: 0.347165  [38464/60000]\n",
      "loss: 0.529711  [44864/60000]\n",
      "loss: 0.388270  [51264/60000]\n",
      "loss: 0.650194  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.305807 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.316349  [   64/60000]\n",
      "loss: 0.316585  [ 6464/60000]\n",
      "loss: 0.403677  [12864/60000]\n",
      "loss: 0.473639  [19264/60000]\n",
      "loss: 0.494556  [25664/60000]\n",
      "loss: 0.469674  [32064/60000]\n",
      "loss: 0.297777  [38464/60000]\n",
      "loss: 0.646267  [44864/60000]\n",
      "loss: 0.397708  [51264/60000]\n",
      "loss: 0.571233  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.302132 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.275205  [   64/60000]\n",
      "loss: 0.331553  [ 6464/60000]\n",
      "loss: 0.325747  [12864/60000]\n",
      "loss: 0.488978  [19264/60000]\n",
      "loss: 0.403896  [25664/60000]\n",
      "loss: 0.412279  [32064/60000]\n",
      "loss: 0.258880  [38464/60000]\n",
      "loss: 0.533070  [44864/60000]\n",
      "loss: 0.359803  [51264/60000]\n",
      "loss: 0.641415  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.299993 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.264623  [   64/60000]\n",
      "loss: 0.429055  [ 6464/60000]\n",
      "loss: 0.460120  [12864/60000]\n",
      "loss: 0.472345  [19264/60000]\n",
      "loss: 0.303162  [25664/60000]\n",
      "loss: 0.295047  [32064/60000]\n",
      "loss: 0.323232  [38464/60000]\n",
      "loss: 0.444278  [44864/60000]\n",
      "loss: 0.302649  [51264/60000]\n",
      "loss: 0.501447  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.307472 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.209489  [   64/60000]\n",
      "loss: 0.357936  [ 6464/60000]\n",
      "loss: 0.331166  [12864/60000]\n",
      "loss: 0.471264  [19264/60000]\n",
      "loss: 0.403788  [25664/60000]\n",
      "loss: 0.327715  [32064/60000]\n",
      "loss: 0.387396  [38464/60000]\n",
      "loss: 0.590024  [44864/60000]\n",
      "loss: 0.365534  [51264/60000]\n",
      "loss: 0.473515  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.297573 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, net, opt)\n",
    "    test(test_dataloader, net)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4945823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack.0.weight\n",
      "stack.0.bias\n",
      "stack.1.weight\n",
      "torch.Size([100])\n",
      "stack.1.bias\n",
      "torch.Size([100])\n",
      "stack.4.weight\n",
      "stack.4.bias\n",
      "stack.5.weight\n",
      "stack.5.bias\n",
      "stack.8.weight\n",
      "stack.8.bias\n",
      "stack.9.weight\n",
      "stack.9.bias\n",
      "stack.12.weight\n",
      "stack.12.bias\n",
      "stack.13.weight\n",
      "stack.13.bias\n",
      "stack.16.weight\n",
      "stack.16.bias\n",
      "stack.17.weight\n",
      "stack.17.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name)\n",
    "    if name.startswith('stack.1.'):\n",
    "        print(param.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c0164391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> ('', FPNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): StraightThroughEstimator()\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.1, inplace=False)\n",
      "    (7): StraightThroughEstimator()\n",
      "    (8): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (9): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout(p=0.1, inplace=False)\n",
      "    (11): StraightThroughEstimator()\n",
      "    (12): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (13): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout(p=0.1, inplace=False)\n",
      "    (15): StraightThroughEstimator()\n",
      "    (16): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (17): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "for idx, m in enumerate(net.named_modules()):\n",
    "    print(f'{idx} -> {m}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8ddb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
